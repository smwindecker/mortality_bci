---
title: "Mortality Notes"
author: "J Camac"
date: "9 July 2014"
output: pdf_document
bibliography: data/refs.bib
csl: downloads/style.csl
---

###Background

[@kleinbaum_survival_2005]

Plant mortality and the processes affecting it are integral to understanding vegetation dynamics. However, few vegetation dynamic models explicitly simulate mortality (Hawkes 2000), and those that have, do so using little process-based information. For example, many models that account for plant mortality by assuming mortality rates are constant (Thorton 2007m White 2000, Delbart et al 2010) or that they change when a threshold has been surpassed (Sitch et al 2003, Sato et al 2007). These simplifications are a result of a lack of process-based information on what causes mortality rates to vary temporally, spatially and within and between species (Hawkes 2000, McDowell et al 2011). In part, this lack of process-based knowledge is a consequence of researchers placing greater emphasis on delimiting what influences plant growth (Hawkes 2000). But it is also due to the difficulties associated with modelling and estimating mortality rates. 

Temporal patterns in plant mortality are highly variable and episodic (Burgmann 1994). Mortality rates also vary between species and are strongly influenced by multiple biotic and abiotic factors that may interact with one another (e.g. drought and herbivory: McDowell 2011). Because of this complexity, improving process-based understanding of mortality requires monitoring large numbers of species and individuals across entire life-cycles and across multiple biotic and abiotic gradients. More importantly, it requires the cause of death to be known for each individual. However, few, if any, data meet all these requirements. Rather, most available data comes from monitoring programs that are usually shorter than many plants lifespans (Bugmann 1996), and that focus on single species at single sites. Furthermore, because of the inherent difficulty of defining the cause of death, most monitoring programs do not delimit the cause of death for each individual.

Consequently, there are very few mechanistic mortality models. In a review of 61 woody plant mortality models, Hawke (2000) found that only 4 were mechanistic and all these were concerned with carbon budgets. In these models mortality occurred when carbon supply was insufficient for growth (e.g. Friend et al. 1997, Bossel 1986, Weinstein et al 1991, Bugmann et al 1997; Fisher et al 2010). By contrast, the remaining 57 models were empirical and included forest yield models (Guan and Gertner 1991), gap models (Dale et al 1985), plant-environment models (King and Grant 1996) and spatial models (Jeltsch et al 1997). These empirical mortality models could be either deterministic (REFS) or stochastic (REFS) and typically included correlations of one or multiple, abiotic and biotic processes such as competition (REF), climate (REF), age (REF), size (REF) and growth rate (REF). 

More recently, researchers have used plant traits to determine why some species are more predispositioned to die under particular conditions than others.

One consistent finding among several phenomological models is that mortality rates tend to be U-shaped. That is, small and large plants are more prone to mortality relative to intermediate sized plants. However, the problem with these models is that most have been fitted for single species and thus may not accurately predict mortality in other species.  


#How have people attempted modelling mortality?
- In order to capture the U-shaped mortality researchers have used a variety of models to capture broad patterns. These include running seperate models for small and large plants, the use of polynomials, or the use of non-parameteric approaches that do not assume an underlying curve.
- However, the problem with such approaches is that they do not attempt to explain the underlying mechanisms that result in U-shaped mortality.
- Some have suggested that certain hazards influence different parts of the U-shape curve. For example, competitive process influence mortality when individuals are small and less so when they are large. Whereas the oppose is true for events such as windthrow.
- Furthermore, the vast majority of these empirical models have been conducted for individual species, and thus are of limited use for more applying to applying to other species.


#What do we know about mortality in plants?
Evidence suggests that mortality is U-shaped for most plants.
We also know that plant survival is influenced by multiple hazards (fire, herbivory, climate, drought, competition and windthrow)

#Traits
More recently ecologists have used traits in an attempt to obtain more generality. The vast majority of this research has focused on how traits influence growth rates, with very few studies examining trait effects on mortality.
Those that have, have reported that traits such as wood density can significantly influence rates of mortality. The logic here is that wood density conveys additional resources into structural properties and thus makes plants more resistant to breakage and invertebrate attack. However, as far as I am aware, all these studies have assumed that the effect of traits remains constant and does not change with size.

#Solution

Many modellers have called for more mechanistic al- gorithms in plant growth models and see the path
towards improvement as a reformulation of mor- tality algorithms to better reflect the physiological base of a plant (e.g. Loehle and LeBlanc, 1996). (Hawke)




Based on the information above I have three primary objectives:

1) Examine whether the effects of wood density are growth dependent or growth independent.
#Current JAGS model
```{r, eval=FALSE}
model <- function(x) {
  for(it in 1:n.obs) {
  	
		died[it] ~ dbern(p[it])
		cloglog(p[it]) <- max(-9999, min(9999,  ln.census + log(cd0*exp(-cd1 * wd[spp[it]]) + cd2 * exp(-cd3 * dbh.gr[it]))))
	}
	
	#Priors
  cd0 ~ dlnorm(0, 0.0001)
  cd1 ~ dlnorm(0, 0.0001)
	cd2 ~ dlnorm(0, 0.0001)
	cd3 ~ dlnorm(0, 0.0001)
	
}
    test2<-     jags.parallel(model.file = model,
                 n.iter = 4000,
                 data= names(data), 
                 envir=list2env(data),
                 inits = NULL,
                 parameters.to.save = c('cd0','cd1','cd2','cd3'))
```

#Potential Stan Model
```{r, eval=FALSE}
library(parallel)
library(rstan)

cat('
  data {
		int<lower=0> N;
		int<lower=0, upper=1> M[N];
		vector[N] ln_T;
		vector[N] wd;
		vector[N] gr;
	
	}
	parameters {
		real<lower=0> c0;
		real c1;
		real<lower=0> c2;
		real<lower=0> c3;
		
	} 
	model {
		for (n in 1:N)
			M[n] ~ bernoulli(inv_cloglog(ln_T + log(c0 * exp(-c1 * wd[n]) + c2 * exp(-c3 * gr[n]))));
	}
', file=(StanModel <- tempfile())
		
			
BCImodel <- sflist2stanfit(
	mclapply(
		1:4,
		function(i) {
			stan(file=StanModel, data=BCIdata, seed=123, chains=1, chain_id=i, refresh=-1)
			}, 
		mc.cores=2
	)
)
```

2) Examine whether the effects of wood density varies with plant size.
3) Write a literature review summarising how plant traits influence mortality across multiple hazards (e.g. wind throw, drought, fire, disease, herbivory)
4) Build a process-based model based on what we have learnt from the above objectives.

#Objective 1

As far as I am aware, there does not appear to be an integrated review of how traits influence various hazards, or how they vary with size.
Most trait analysis of mortality has either ignored the cause of death or has been related to very specific forms of mortality. For example, there are several studies that highlight suite of traits that minimise death by fire, but less so on other hazards such as wind throw and climatatic extremes.
In order to remedy this. I am to write a brief literature review highlighting the primary hazards plants are exposed to and how various traits have been linked to decreased or increased susceptibility.

In order to achieve this I plan to use google scholar and...

#Objective 2
Include maths here

#Objective 3
Preliminary thoughts

Modelling survival and mortality within a population is of fundamental importance in ecology, epidemiology, demography, engineering and economics. It is particularly

Burgman et al. (1994) points out the significance of tree mortality for forest yield and growth rates, and Pacala et al. (1996) shows the importance of species mortality rates in forest succession.What is clear is that mortality is very difficult to model owing to its variable and episodic nature (Burgman et al., 1994) (Hawke)

#Difficulty in modelling mortality
The complexity of environmental stresses and lack of process information of woody plant mortality has however led to the wide use of empirical algorithms.These have many problems, including data intensity and spatial and temporal specificity. Such problems render mortality simulation prone to error and weak in response to environmental change.  (Hawke)

Describing size-specific mortality patterns can be especially difficult, due to few trees in larger size classes. (Hurst)



###Aim:
1. Determine traits influence the likelihood of a particular hazard resulting in death.
2. Determine whether instantaneous mortality rates are commonly U-shaped as a function of dbh.
3. Examine whether trait effects on instantaneous mortality rates vary with individual size and growth rate
4. Build a process-based mortality model that encapsulates how the combination of various hazards and traits can result in various mortality curves.

###Hypotheses
1. The most common hazards that can result in plant death are all size dependent and include:
**Competition**: This hazard will most strongly affect smaller individuals because they are more at risk of being shaded compared to larger plants. Traits affecting the likelihood of competition resulting in death will be correlated with shade tolerance such as *LMA* and *wood density*.

**Herbivory**: This hazard will most strongly affect small individuals more susceptible to complete foliage loss or being consumed entirely. Traits affecting the liklihood of herbivory resulting in death will be correlated with herbivory preference (e.g. *leaf nitrogen*), resistance (e.g. *wood density*) and persistance (*resprouting capabilities*).

**Fire**: This hazard is likely to be size dependent with small individuals more suspectible to fire compared to larger plants. This is because for small/juvenile plants will are less likely to have developed fire-resistant traits. They are also lower in stature making their leaves exposed to both low severity and high severity fires. Traits affecting the likelihood of fire resulting in death will be correlated with fire-resistance (e.g. bark thickness) and persistance (e.g. resprouting)

**Drought/Extreme heat/ Extreme cold**: These hazard is likely to..

###Factors influencing small individuals
```{r, echo=FALSE}
par(xaxs='i', yaxs='i', mfrow= c(3,2))
curve(1/(1+((1/0.99)-1)*exp(5*x)), ylim=c(0,1), xlim=c(0, 1.2), xaxt='n', ylab= 'Mortality rate', xlab='Size', main='Death by fire', lwd=2)
axis(1, at=c(0,1.2), labels=c('Small', 'Large'))

curve(1/(1+((1/0.99)-1)*exp(7*x)), ylim=c(0,1), xlim=c(0, 1.2), xaxt='n', ylab= 'Mortality rate', xlab='Size', main='Death by drought',lwd=2)
axis(1, at=c(0,1.2), labels=c('Small', 'Large'))

curve(1/(1+((1/0.99)-1)*exp(7*x)), ylim=c(0,1), xlim=c(0, 1.2), xaxt='n', ylab= 'Mortality rate', xlab='Size', main='Death by high temperatures',lwd=2)
axis(1, at=c(0,1.2), labels=c('Small', 'Large'))

curve(1/(1+((1/0.99)-1)*exp(7*x)), ylim=c(0,1), xlim=c(0, 1.2), xaxt='n', ylab= 'Mortality rate', xlab='Size', main='Death by low temperatures',lwd=2)
axis(1, at=c(0,1.2), labels=c('Small', 'Large'))

curve(1/(1+((1/0.99)-1)*exp(7*x)), ylim=c(0,1), xlim=c(0, 1.2), xaxt='n', ylab= 'Mortality rate', xlab='Size', main='Death by herbivory',lwd=2)
axis(1, at=c(0,1.2), labels=c('Small', 'Large'))

curve(1/(1+((1/0.99)-1)*exp(15*x)), ylim=c(0,1), xlim=c(0, 1.2), xaxt='n', ylab= 'Mortality rate', xlab='Size', main='Death by light competition', lwd=2)
axis(1, at=c(0,1.2), labels=c('Small', 'Large'))
```

###Factors influencing large individuals
```{r, echo=FALSE}
par(xaxs='i', yaxs='i',mfrow=c(1,3))
curve(1/(1+((1/0.02)-1)*exp(-10*x)), ylim=c(0,1), xlim=c(0, 1.2), xaxt='n', ylab= 'Mortality rate', xlab='Size', main='Death by wind fall', lwd=2)
axis(1, at=c(0,1.2), labels=c('Small', 'Large'))

curve(0.9/(1+((0.9/0.2)-1)*exp(-7*x)), ylim=c(0,1), xlim=c(0, 1.2), xaxt='n', ylab= 'Mortality rate', xlab='Size', main='Death by falling neighbour',lwd=2)
axis(1, at=c(0,1.2), labels=c('Small', 'Large'))

curve(1/(1+((1/0.001)-1)*exp(-8*x)), ylim=c(0,1), xlim=c(0, 1.2), xaxt='n', ylab= 'Mortality rate', xlab='Time', main='Death by disease',lwd=2)
axis(1, at=c(0,1.2), labels=c('0', 'infinity'))
```

###Traits are likely to affect shape of these hazard rates
```{r, echo=FALSE}
par(xaxs='i', yaxs='i', mfrow=c(1,2))
curve(1/(1+((1/0.02)-1)*exp(-10*x)), ylim=c(0,1), xlim=c(0, 2), xaxt='n', ylab= 'Mortality rate', xlab='Size', main='Death by wind fall')
curve(1/(1+((1/0.02)-1)*exp(-5*x)), ylim=c(0,1), xlim=c(0, 2), xaxt='n', ylab= 'Mortality rate', xlab='Size', main='Death by wind fall', add=T, col='red', lty=2, lwd=2)
axis(1, at=c(0,2), labels=c('Small', 'Large'))
legend(0.7,0.2, legend = c('low wd', 'high wd'), col=c('black','red'), lty=c(1,2), bty = 'n', lwd=2, cex=2,)

curve(1/(1+((1/0.02)-1)*exp(-10*x)), ylim=c(0,1), xlim=c(0, 2), xaxt='n', ylab= 'Mortality rate', xlab='Size', main='Death by wind fall')
curve(1/(1+((1/0.02)-1)*exp(-5*x)), ylim=c(0,1), xlim=c(0, 2), xaxt='n', ylab= 'Mortality rate', xlab='Size', main='Death by wind fall', add=T, col='red', lty=2, lwd=2)
axis(1, at=c(0,2), labels=c('Small', 'Large'))
legend(0.7,0.2, legend = c('low severity', 'high severity'), col=c('black','red'), lty=c(1,2), bty = 'n', lwd=2, cex=2,)
```

## Survival analysis

- Most people model survival curves
- However, here we are interested in determining how trait alter hazards.

The survival function is intimately related to the **hazard** or **instantaneous mortality function**,  denoted $\lambda(t)$, which gives the event rate at time $t$ conditional on survival until time $t$:

\begin{equation} \label{eq:lambda} \lambda(t) = \lim_{dt \rightarrow 0} \frac{\Pr(t \leq T < t+dt)}{dt\cdot S(t)} = -\frac{S'(t)}{S(t)}.\end{equation}

This means that:
\begin{equation}
Survival(t) = \lambda_1(t) \times \lambda_2(t) \times \lambda_3(t)... \times \lambda_n
\end{equation}

### Here I plan to model hazards by...
####EG Fire

\begin{equation}
\lambda(t) = f(age)^{-1} \times \int_{0}^{\infty} p(intensity|age) \times \Pr(\textrm{Death in fire of intensity}\, i) \, \textrm{d}i
\end{equation}

\begin{equation}
\Pr(Death)  = \alpha + \beta_1 \times Size + \beta_2 \times Resprouter + \beta_3 \times Bark thickness
\end{equation}


##OTHER STUFF
Below are some excerpts from William Morris's thesis on mortality of trees.

The **finite mortality rate**, $M$, ignoring recruitment, is the complement of the ratio of final populatio size, $N_T$, to initial population size, $N_0$, divided by the length of the observation period, $T$,


\begin{equation} \label{eq:FiniteMort}
M = 1 -\frac{N_T/N_0}{T}
\end{equation}

However, in order to infer an unbiased expected proportion of dying individuals for periods shorter or longer than that used to calculate finite mortality one must calculate the **instantaneous mortality**, $M_T$:

\begin{equation} \label{eq:InstMort}
M_T = 1-\textrm{exp}(-\lambda T)
\end{equation}

where

\begin{equation} \label{eq:lambda}
\lambda = - \frac{\textrm{log}_e(1-M)}{T}.
\end{equation}

This function is widely used to describe the loss of individuals from a population over time. Here, when $M_T$ and $\lambda$ are more or less equivilent mortality rates are low.

Calculating mortality rate is made more complicated when multiple censuses (a period of time in which mortality risk is being assessed, where census interval = $T$) are considered, partlicalrly when census interval lengths vary. In such cases equations \ref{eq:FiniteMort} and \ref{eq:InstMort} cannot be used because $T$ is not dixed and substituting $T$ with average interval length has been shown to underestimate mortality (Kubo et al., 2000). This is a particular problem with large-scale monitoring programs such as BCI where the period of time between revisits of individual trees varies within a signle census because there are too many individuals for observations to be made simultaneously. Datasets such as BCI can take more than a year to complete an entire census.

When $T$ varies within a mortality dataset, estimates of population mortality rate will be biased if this variation is not accounted for (e.g. by assuming a mean value for $T$ and using equation \ref{eq:InstMort}. In order to achieve an unbiased estimate of $M_T$ and $\lambda$ when census length varies, maximum likelihood (Kubo et al, 2000) or Bayesian (He, 2003) methods can be used, which allow $T$ to be considered a continous variable.

The methods so far assume $\lambda$ is fixed in space and time, between individuals and over the lifespan of an individual. Often these assumptions are not met because individual hazard rates vary. Heterogeneous hazard biases estimates of population mortality rates (Sheil & May 1996) and this bias is greater for longer census intervals (Zens & Peart 2003). The need for unbiased estimates of mortality, despite the hazard heterogeneity present in data from forests and woodlands, has lead to the development and application of methods that move beyond considering mortality at the population level and directly modelling hazard of individual trees (Zens & Peart, 2003).

The logistic regression family of methods are the most common individual-based approach used to analyse tree mortality data (see Breece, Kolb & Dickson, 2008, Carus 2010, Flewelling & Monserud, 2002). Logistic regression models consider tree death, $\textrm{Pr}(y_i = 1)$, as a series of binomially distributed data with the probability of observing a death as function of a set of covariates, $X_i$, and associated coefficients, $\beta$ related to data via the logit link function.

\begin{equation} \label{eq:logit}
\textrm{Pr}(y_{i} = 1) = \textrm{logit}^{-1}(\beta X_i)
\end{equation}

The logit function, $\textrm{log}_e(p/(1 - p))$, transforms a quantity bound within the unit interval, such as probability, $p$, to cary between negative infinity and infinity. By relating mortality to covariates that can explain differences in death rate, individual based methods such as logistic regression can reduce the bias found in population rate estimates when individuals have variable hazard (Zens & Peart, 2003).

The complementary log-log (cloglog) link, $\textrm{log}_e(-\textrm{log}_e(1-p))$, is another link that can be used to estimate mortality rates.
The advantage of the cloglog link is that it is equivalent to standard survival analysis... NEED MORE INFO. It also reduces bias due to long and variable census intervals (BY?).
By adding the census interval $T$ to equation \ref{eq:logit} and substituting the logit link with a cloglog link yields

\begin{equation} \label{eq:cloglog}
\textrm{Pr}(y_{i} = 1) = \textrm{cloglog}^{-1}(\beta X_{i} + \textrm{log}(T))
\end{equation}


y = log(-log(1-P))

y = log(e) + log(1/(1-P)))
e^y = (1/(1-P))
e^y*(1-P) = 1
e^y - Pe^y = 1


-e(e^y) + 1

1 - e(e^y)



### MULTI-LEVEL NOTES:

####From Hedeker et al 2014

Nice summary of why multi-level models are essential for accounting for non-independence in nested datasets.

"An important question is then to determine the degree to which covariates are related to substance use initiation. In these studies it is often of interest to model the student outcomes while controlling for the nesting of students in classrooms and/or schools. In analysis of such grouped-time initiation (or survival) data, use of grouped-time regression models that assume independence of observations [Thompson, 1977; Prentice & Gloeckler, 1978; Allison, 1982] is therefore problematic because of this clustering of students. More generally, this same issue arises for other types of clustered datasets in which subjects are observed nested within various types of clusters (e.g., hospitals, firms, clinics, counties), and thus cannot be assumed to be independent. To account for the data clustering, multilevel models (also called hierarchical linear or mixed models) provide a useful approach for simultaneously estimating the parameters of the regression model and the variance components that account for the data clustering [Goldstein, 1995; Raudenbush & Bryk, 2002]."

## TWO REVIEW PAPERS TO READ Pickles et al 1995 & Hougaard 1995 ###

Lee et al 1992 has developed continuous0time survival models. However, the application of these models to grouped or discrete-time survival data is generally not recommended because of the large number of ties that result.

Instead, models specifically developed for grouped or discrete-time survival data have been proposed.

Both Han & Hausman (1990) and Scheike & Jensen (1997) have described proportional hazards models incorporating a log-gamma distribution specification of heterogeneity. Furthermore, Ten Have (1996) developed a discrete-time proportional hazards survival model incorporating a log-gamma random effects distribution, additionally allowing for ordinal survival and failure categories. Ten Have & Uttal (1994) used Gibbs samplng to fit a continuation ratio logit model with multiple normally distributed random effects.

## IMPORTANT NOTE ON link function

Doksum & Gasko (1990) note, that large amounts of high quality data are often necessary for link function selections to be relevant. McCullagh (1980) notes that the link function choice should be based primarily on ease of interpretation.

## Multilevel model that treats each individual's survival time as a set of dichotomous observations indicating whether or not an individual failed in each time unti until a person either experiences the event or is censored. This type of model is extensively described in Singer & Willett (2003) & is illustrated in Reardon et al (2002).

This approach is particularly useful for handling time-dependent covariates and fitting non-proportional hazards models because the covariate values can change across each individual's Tij timepoints.


# REFERENCES








